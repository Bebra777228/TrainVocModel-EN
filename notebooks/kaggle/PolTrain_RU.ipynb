{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["XnIUS5P9VauG","O_27mvQ9mZjQ","8q3V33sNvi6i","QW3zegy0fj1G","h76D42owRGmD","fZ3Kl6DJmtSF","hS9N_NgbghFm","LcuZU1pPglXU"]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>PolTrain 05.01.25 - Politrees\n    \n---\n\n**<center><font color='#FF8C00'>.•.•●•.•●⬤●•. Буду рад вашей поддержке! .•●⬤●•.•●•.•.</font>**\n\n<center><a href=\"https://www.donationalerts.com/r/politrees\" title=\"Перейти к Donationalerts\">\n   <img src=\"https://upload.wikimedia.org/wikipedia/ru/a/ad/DA_Logo_Color.svg\" width=\"200\" alt=\"Donationalerts\">\n</a>\n\n**<center>Делаю модели на заказ. Подробности в [Telegram](https://t.me/Politrees2)**\n\n**<center>Будьте в курсе всех обновлений и новостей! Подписывайтесь на мой [Telegram-канал](https://t.me/politrees)**\n\n---","metadata":{}},{"cell_type":"code","source":"# ===== ПУТЬ К РАБОЧЕЙ ПАПКЕ ===== #\nTrain_dir = \"/kaggle/working/PolTrain\"\n\n# ===== ИМПОРТЫ ===== #\nimport os\nimport torch\nfrom ipywidgets import Button\nfrom IPython.display import clear_output\n\n# ===== ПРОВЕРКА НА ДОСТУПНОСТЬ GPU ===== #\nprint(\"Проверка доступности GPU...\")\nif torch.cuda.is_available():\n    print(\"GPU доступен!\")\n    device = torch.device(\"cuda\")\nelse:\n    print(\"GPU недоступен!\")\n    device = torch.device(\"cpu\")\n    raise Exception('К сожалению, у вас нет доступа к GPU на вашем текущем аккаунте. Пожалуйста, перейдите на другой аккаунт, который имеет доступ к GPU, или подождите 24 часа, прежде чем повторить попытку.')\n\nif not os.path.exists('/kaggle/working/dataset'):\n    os.makedirs('/kaggle/working/dataset')\n\n# ===== КЛОНИРОВАНИЕ РЕПОЗИТОРИЯ ===== #\nif not os.path.isdir(f'{Train_dir}'):\n    print(\"\\nКопирование репозитория...\")\n    !git clone https://github.com/Bebra777228/TrainVocModel-EN {Train_dir} &> /dev/null\n\n# ===== ПЕРЕХОД К РАБОЧЕЙ ПАПКЕ И ОЧИСТКА КОНСОЛИ ===== #\n%cd {Train_dir}\nclear_output()\n\n# ===== ВЫВОД СООБЩЕНИЙ ОБ УСТАНОВКЕ ===== #\nprint(\"\\nУстановка может занять до 5 минут. Пожалуйста, подождите...\")\nprint(\"По любым вопросам, пишите в ТГ: https://t.me/+GMTP7hZqY0E4OGRi\")\n\n# ===== УСТАНОВКА ЗАВИСИМОСТЕЙ И ПАКЕТОВ ===== #\n!pip install --no-cache-dir -qq pip==23.1 &> /dev/null\n!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n!pip install --no-cache-dir -qq faiss-cpu==1.7.3 &> /dev/null\n!apt -y install -qq aria2 &> /dev/null\n\n# ===== УСТАНОВКА НЕОБХОДИМЫХ МОДЕЛЕЙ ===== #\n!python download_files.py \"./assets/\" \"contentvec_base\" &> /dev/null\n\n# ===== ОЧИСТКА КОНСОЛИ И ВЫВОД КНОПКИ \"Готово\" ===== #\nclear_output()\nButton(description=\"\\u2714 Готово\", button_style=\"success\")","metadata":{"id":"Sb5fzhzEXK8X","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Train_dir = \"/kaggle/working/PolTrain\"\n%cd {Train_dir}\nclear_output()\n\nimport os\nimport re\nfrom ipywidgets import Button\nfrom IPython.display import clear_output\n\n# Дайте имя своей модели `(Например - Sanya)`:\nmodel_name = 'Имя датасета'\n\n# Путь к папке с аудио `(датасет)`:\ndataset_folder = '/kaggle/input/Имя датасета'\n\n# Частота дискретизации:\nsample_rate = \"40k\"   # 32k, 40k или 48k\n\n# Метод извлечения тона:\nf0_method = \"rmvpe+\"   # rmvpe+, rmvpe или harvest\n\n# Алгоритм извлечения индекса:\nindex_algorithm = \"Auto\"   # Auto, Faiss или KMeans\n\n# ПРОЦЕНТАЖ | Определяет длину фрагментов / По умолчанию: 3с.700мс.\npercentage = 3.7      # Рекомендуемые значения: 3-5\n\n\n# ================================================== #\n\n\n# ===== ПРОВЕРКА НА ПРАВИЛЬНОСТЬ ВВОДА ИМЕНИ МОДЕЛИ ===== #\nif not re.match(r'^[a-zA-Z0-9_]+$', model_name):\n    raise ValueError(\"Имя модели содержит недопустимые символы или пробелы!\")\nelse:\n    os.makedirs(f'./logs/{model_name}', exist_ok=True)\n\n# ===== ПРОВЕРКА НА СУЩЕСТВОВАНИЕ ПАПКИ С ДАТАСЕТОМ ===== #\nif not os.path.exists(dataset_folder):\n    raise FileNotFoundError(\"Папка с набором данных не существует!\")\nif not os.listdir(dataset_folder):\n    raise FileNotFoundError(\"Папка с набором данных пуста!\")\n\n# ===== ПРЕОБРАЗОВАНИЕ sample_rate В ЦЕЛОЕ ЧИСЛО ===== #\nsr = int(sample_rate.rstrip(\"k\")) * 1000\n\n# ===== ОБРАБОТКА ДАННЫХ И СОЗДАНИЕ ИНДЕКСА ===== #\nerror_message = \"Ошибка при предварительной обработке данных. Убедитесь, что в наборе данных есть звук и что он достаточно громкий.\"\n\nwith open(f'./logs/{model_name}/logfile.log', 'a') as f:\n    !python {Train_dir}/infer/modules/train/preprocess.py {dataset_folder} {sr} 2 ./logs/{model_name} False {percentage}\nwith open(f'./logs/{model_name}/logfile.log','r') as f:\n    if 'Обработка успешно завершена!' in f.read():\n        clear_output()\n    else:\n        raise Exception(error_message)\n    \nwith open(f'./logs/{model_name}/logfile.log', 'a') as f:\n    !python {Train_dir}/infer/modules/train/extract_f0.py 1 0 0 ./logs/{model_name} False {f0_method}\nwith open(f'./logs/{model_name}/logfile.log','r') as f:\n    if 'Тон извлечен!' in f.read():\n        clear_output()\n    else:\n        raise Exception(error_message)\n\nwith open(f'./logs/{model_name}/logfile.log', 'a') as f:\n    !python {Train_dir}/infer/modules/train/extract_feature.py 1 0 ./logs/{model_name} v2 False\nwith open(f'./logs/{model_name}/logfile.log','r') as f:\n    if 'Все признаки извлечены!' in f.read():\n        clear_output()\n    else:\n        raise Exception(error_message)\n\n\n!python {Train_dir}/infer/modules/train/extract_index.py ./logs/{model_name} v2 {index_algorithm}\n\n\n# ================================================== #\n#                ОПИСАНИЕ ПАРАМЕТРОВ:                #\n\n# model_name - Имя вашей модели. Это название будет использоваться для создания папки, где будут храниться все результаты обучения и лог-файлы. Разрешены только английские буквы, цифры и символ подчёркивания (`_`). Пробелы и специальные символы запрещены.\n\n# dataset_folder - Путь к папке, где находятся ваши аудиофайлы (датасет). Убедитесь, что папка содержит аудиофайлы, которые вы хотите использовать для обучения модели RVC. Эти аудиофайлы будут преобразованы в признаки, которые используются для обучения. Рекомендуется использовать не менее 10 минут чистого аудио без шумов или пауз. Рекомендуемые форматы файлов: .wav или .flac.\n\n# sample_rate - Частота дискретизации аудиофайлов. Этот параметр определяет, с какой частотой будут обрабатываться ваши аудиофайлы. Выбор частоты влияет на качество и скорость обработки:\n# * 32k - 32.000 Гц (низкая частота, быстрая обработка, но менее качественный звук).\n# * 40k - 40.000 Гц (стандартный выбор для большинства задач, хорошее соотношение скорости и качества).\n# * 48k - 48.000 Гц (высокая частота, более качественный звук, но требует больше ресурсов).\n\n# f0_method - Метод извлечения тона голоса. Этот параметр определяет, как программа будет определять высоту звука (F0) в ваших аудиофайлах. Выбор метода влияет на точность и скорость обработки:\n# * harvest - Метод, обеспечивающий лучшее воспроизведение тонов, но медленнее и может давать ошибки на начальных этапах. Подходит для акапелл.\n# * rmvpe - Комбинация методов Pm и Crepe, обеспечивающая высокую точность и скорость. Наиболее верный метод для модели голоса.\n# * rmvpe+ - Улучшенная версия Rmvpe, обеспечивающая высокую точность и скорость обработки. Подходит для сложных аудиофайлов.\n\n# index_algorithm - Алгоритм кластеризации данных. Этот параметр определяет, как программа будет группировать данные для обучения модели RVC. Выбор алгоритма зависит от размера вашего датасета:\n# * Auto - Программа автоматически выбирает лучший метод в зависимости от размера вашего датасета. Рекомендуется для большинства случаев.\n# * Faiss - Мощный алгоритм для поиска ближайших соседей, эффективен для больших датасетов. Подходит для сложных и объёмных данных.\n# * KMeans - Простой и быстрый алгоритм кластеризации, который делит данные на группы (кластеры). Подходит для средних и больших датасетов, особенно если вы хотите сэкономить время.\n\n# По поводу ресурсов, которые предоставляет Google Colab, могу сказать следующее: оставьте этот параметр на Auto.\n# Если же вы хотите выбрать между двумя алгоритмами, то:\n# * Faiss — подходит для наборов данных, содержащих менее одного часа информации.\n# * KMeans — рекомендуется для наборов с более чем часовым объёмом данных.\n# Конечно, вы можете попробовать запустить Faiss и на часовом наборе данных, но, думаю, что либо Google Colab не сможет справиться с нагрузкой, либо процесс создания индекса займёт слишком много времени, и вы устанете ждать, либо на колабе закончатся бесплатные ресурсы и вам не хватит времени на тренировку.\n","metadata":{"cellView":"form","id":"c9a4PKyP1yQE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Train_dir = \"/kaggle/working/PolTrain\"\n\nimport os\nimport json\nimport pathlib\nimport traceback\nfrom random import shuffle\nfrom urllib.parse import urlparse\nfrom IPython.display import clear_output\nfrom subprocess import PIPE, STDOUT, Popen\n\n%cd {Train_dir}\nnow_dir=os.getcwd()\n\n# Общее количество эпох для тренировки:\nepochs = \"500\"   # от 1 до бесконечности\n\n# Частота сохранения моделей на диск:\nsave_epoch = \"100\"   # от 5 до 100, но лучше не менять, так как продолжить тренировку тут нельзя\n\n# Оптимизаторы:\noptimizer = \"AdamW\" # AdamW, RAdam\n\n# Предварительно обученные модели:\npretrain = \"Snowie v3\"   # Default, Snowie v3, TITAN-Medium\n\n# Default - Стандартный претрейн сделанный разработчиками RVC\n# Snowie v3 - Русский претрейн / by MUSTAR\n# TITAN-Medium - Английский претрейн / by Blaise\n\n# Пользовательские предварительно обученные модели:\ncustom_pretrained = False   # True - включено / False - выключено\nd_pretrained_link = \"\"      # Ссылка на D файл\ng_pretrained_link = \"\"      # Ссылка на G файл\n# Cсылки можно взять тут: https://huggingface.co/Politrees/RVC_resources/tree/main/pretrained/v2\n\n# Количество фрагментов датасета, обрабатываемых за один шаг:\nbatch_size = 8   # от 4 до 16\n\n# Экономия памяти при тренировке:\nfp16_run = False   # True - включено / False - выключено\n\n# Включить TensorBoard:\ntensorboard = False   # True - включено / False - выключено\n\n\n# ============================================ #\n# ===== НИЖЕ КОД, ЗАПУСКАЮЩИЙ ТРЕНИРОВКУ ===== #\n\nparam_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\nhugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gin\" + \"gfa\" + \"ce.co\" + \"/Poli\" + \"tree\" + \"s/RV\" + \"C_res\" + \"ourc\" + \"es/re\" + \"solv\" + \"e/ma\" + \"in/pret\" + \"rain\" + \"ed/v2\"\n\npretrain_outpath = \"/content/pretrained_models\"\n!rm -r {pretrain_outpath}  &> /dev/null\n\nclear_output()\nprint(\"Запуск...\")\n\nmodels = {\n    \"Default\": [\n        (f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D.pth\"),\n        (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G.pth\"),\n    ],\n    \"Snowie v3\": [\n        (f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D.pth\"),\n        (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G.pth\"),\n    ],\n    \"TITAN-Medium\": [\n        (f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D.pth\"),\n        (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G.pth\"),\n    ],\n}\n\nif custom_pretrained:\n    if d_pretrained_link and g_pretrained_link:\n        d_filename = os.path.basename(urlparse(d_pretrained_link).path)\n        g_filename = os.path.basename(urlparse(g_pretrained_link).path)\n        G_file = f'{pretrain_outpath}/{g_filename}'\n        D_file = f'{pretrain_outpath}/{d_filename}'\n        print(f\"Установка пользовательских претрейнов...\\nG_file - {g_filename}\\nD_file - {d_filename}\")\n        !aria2c {param_aria} {g_pretrained_link} -d {pretrain_outpath} -o {g_filename} &> /dev/null\n        !aria2c {param_aria} {d_pretrained_link} -d {pretrain_outpath} -o {d_filename} &> /dev/null\n    else:\n        raise ValueError(\"Для custom_pretrained необходимо указать ссылки на D и G файлы претрейна.\")\nelse:\n    print(f\"Установка претрейна {pretrain}...\")\n    for f in models[pretrain]:\n        !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n\n    G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n    D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n\ndef click_train(\n    experiment_dir,\n    sample_rate,\n    save_epoch_interval,\n    total_epochs,\n    batch_size,\n    pretrained_G,\n    pretrained_D,\n    gpu_ids,\n    optimizer,\n):\n    exp_dir = f\"{now_dir}/logs/{experiment_dir}\"\n    os.makedirs(exp_dir, exist_ok=True)\n\n    #data_dir = f\"{exp_dir}/data\"\n    f0_dir = f\"{exp_dir}/2a_f0\"\n    f0nsf_dir = f\"{exp_dir}/2b-f0nsf\"\n    gt_wavs_dir = f\"{exp_dir}/0_gt_wavs\"\n    feature_dir = f\"{exp_dir}/3_feature768\"\n\n    names = (\n        set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n        & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n        & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n        & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n    )\n\n    opt = []\n    for name in names:\n        opt.append(\n            f\"{gt_wavs_dir}/{name}.wav|\"\n            f\"{feature_dir}/{name}.npy|\"\n            f\"{f0_dir}/{name}.wav.npy|\"\n            f\"{f0nsf_dir}/{name}.wav.npy|0\"\n        )\n    for _ in range(2):\n        opt.append(\n            f\"{now_dir}/logs/mute/0_gt_wavs/mute{sample_rate}.wav|\"\n            f\"{now_dir}/logs/mute/3_feature768/mute.npy|\"\n            f\"{now_dir}/logs/mute/2a_f0/mute.wav.npy|\"\n            f\"{now_dir}/logs/mute/2b-f0nsf/mute.wav.npy|0\"\n        )\n\n    shuffle(opt)\n\n    with open(f\"{exp_dir}/filelist.txt\", \"w\") as f:\n        f.write(\"\\n\".join(opt))\n\n    if sample_rate == \"40k\":\n        config_path = f\"configs/v1/{sample_rate}.json\"\n    else:\n        config_path = f\"configs/v2/{sample_rate}.json\"\n\n    config_save_path = os.path.join(exp_dir, \"config.json\")\n    if not pathlib.Path(config_save_path).exists():\n        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n            with open(config_path, \"r\") as config_file:\n                config_data = json.load(config_file)\n                config_data[\"train\"][\"fp16_run\"] = fp16_run\n                json.dump(\n                    config_data,\n                    f,\n                    ensure_ascii=False,\n                    indent=4,\n                    sort_keys=True,\n                )\n            f.write(\"\\n\")\n\n    print(\"\\nЗапись файлов завершена\\n\")\n    print(\"Запуск программы...\\n\")\n\n    cmd = (\n        f'python {Train_dir}/infer/modules/train/train.py '\n        f'-e \"{experiment_dir}\" '\n        f'-sr {sample_rate} '\n        f'-se {save_epoch_interval} '\n        f'-te {total_epochs} '\n        f'-bs {batch_size} '\n        f'{\"-pg %s\" % pretrained_G if pretrained_G != \"\" else \"\"} '\n        f'{\"-pd %s\" % pretrained_D if pretrained_D != \"\" else \"\"} '\n        f'-g {gpu_ids} '\n        f'-o {optimizer}'\n    )\n\n    try:\n        p = Popen(\n            cmd,\n            shell=True,\n            cwd=now_dir,\n            stdout=PIPE,\n            stderr=STDOUT,\n            bufsize=1,\n            universal_newlines=True,\n        )\n\n        for line in p.stdout:\n            print(line.strip())\n\n        p.wait()\n\n    except Exception as e:\n        with open(f\"{exp_dir}/error_log.txt\", \"w\") as f:\n            f.write(\"Произошла ошибка:\\n\")\n            f.write(traceback.format_exc())\n        raise Exception(f\"Произошла ошибка: {e}\")\n\n    return \"Программа закрыта.\"\n\nif tensorboard:\n    %load_ext tensorboard\n    %tensorboard --logdir ./logs --port=8888\ntraining_log = click_train(\n    model_name,\n    sample_rate,\n    save_epoch,\n    epochs,\n    batch_size,\n    G_file,\n    D_file,\n    \"0,1\",\n    optimizer,\n)\nprint(training_log)","metadata":{"cellView":"form","id":"WSWzfETu12lS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nimport glob\n\n# Задайте имя ZIP-архива здесь:\nZIP_NAME = \"Model.zip\"\n\ndef check_and_zip_files(model_name, zip_name=ZIP_NAME):\n    base_name = os.path.splitext(zip_name)[0]  # Убираем расширение .zip\n    \n    # Поиск файла .index с учетом возможного различного числа после IVF\n    index_files = glob.glob(f\"/kaggle/working/PolTrain/logs/{model_name}/added_{model_name}_v2.index\")\n    if not index_files:\n        return False\n    index_file_path = index_files[0]\n    index_file_name = os.path.basename(index_file_path).replace(model_name, base_name)\n    \n    pth_file = f\"/kaggle/working/PolTrain/assets/weights/{model_name}.pth\"\n    \n    if os.path.exists(index_file_path) and os.path.exists(pth_file):\n        with zipfile.ZipFile(f\"/kaggle/working/{zip_name}\", 'w') as zipf:\n            zipf.write(index_file_path, index_file_name)\n            zipf.write(pth_file, f\"{base_name}.pth\")\n        return True\n    return False\n\n# После завершения тренировки:\nif check_and_zip_files(model_name):\n    print(f\"Файлы модели упакованы в {ZIP_NAME}\")\nelse:\n    print(\"Не удалось найти файлы модели.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Модель сохраняется на диск автоматически.\n\n---\n\n* Путь к .pth файлу: **PolTrain / assets / weights / [имя модели].pth**\n* Примеры:\n    - **PolTrain / assets / weights / my_model.pth**\n    - **PolTrain / assets / weights / my_model_e10_s500.pth**\n\n---\n\n* Путь к .index файлу:\n**PolTrain / logs / [имя модели] / added_[имя модели]_v2.index**\n* Пример: **PolTrain / logs / my_model / added_my_model_v2.index**","metadata":{"id":"QW3zegy0fj1G"}}]}
{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["XnIUS5P9VauG","O_27mvQ9mZjQ","8q3V33sNvi6i","QW3zegy0fj1G","h76D42owRGmD","fZ3Kl6DJmtSF","hS9N_NgbghFm","LcuZU1pPglXU"]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# PolTrain 17.12.24 - Politrees | by Player1444\n\n---\r\n---\r\n<center>\r\n\r\n**<font color='#FF8C00'>Буду рад вашей поддержке!</font>**\r\n\r\n<a href=\"https://www.donationalerts.com/r/politrees\" title=\"Перейти к Donationalerts\">\r\n   <img src=\"https://upload.wikimedia.org/wikipedia/ru/a/ad/DA_Logo_Color.svg\" width=\"200\" alt=\"Donationalerts\">\r\n</a>\r\n\r\n**Делаю модели на заказ. Подробности в [Telegram](https://t.me/Politrees2)**\r\n\r\n---\r\n---\r\n\r\n**Будьте в курсе всех обновлений и новостей! Подписывайтесь на мой [Telegram-канал](https://t.me/pol1trees)**\r\n\r\n---","metadata":{"id":"r4ihJIzbgfK8"}},{"cell_type":"code","source":"#@title <big>⬇️ **Установка RVC**\n\n# ===== ПУТЬ К РАБОЧЕЙ ПАПКЕ ===== #\nTrain_dir = \"/kaggle/working/TrainingModel\"\n\n# ===== ИМПОРТЫ ===== #\nimport os\nimport torch\nfrom ipywidgets import Button\nfrom IPython.display import clear_output\n\n# ===== ПРОВЕРКА НА ДОСТУПНОСТЬ GPU ===== #\nprint(\"Проверка доступности GPU...\")\nif torch.cuda.is_available():\n    print(\"GPU доступен!\")\n    device = torch.device(\"cuda\")\nelse:\n    print(\"GPU недоступен!\")\n    device = torch.device(\"cpu\")\n    raise Exception('К сожалению, у вас нет доступа к GPU на вашем текущем аккаунте. Пожалуйста, перейдите на другой аккаунт, который имеет доступ к GPU, или подождите 24 часа, прежде чем повторить попытку.')\n\n\nif not os.path.exists('/kaggle/working/dataset'):\n    os.makedirs('/kaggle/working/dataset')\n\n# ===== КЛОНИРОВАНИЕ РЕПОЗИТОРИЯ ===== #\nif not os.path.isdir(f'{Train_dir}'):\n    print(\"\\nКопирование репозитория...\")\n    !git clone https://github.com/Bebra777228/TrainVocModel-EN {Train_dir} &> /dev/null\n\n# ===== ПЕРЕХОД К РАБОЧЕЙ ПАПКЕ И ОЧИСТКА КОНСОЛИ ===== #\n%cd {Train_dir}\nclear_output()\n\n# ===== ВЫВОД СООБЩЕНИЙ ОБ УСТАНОВКЕ ===== #\nprint(\"\\nУстановка может занять до 5 минут. Пожалуйста, подождите...\")\nprint(\"По любым вопросам, пишите в ТГ: https://t.me/+GMTP7hZqY0E4OGRi\")\n\n# ===== УСТАНОВКА ЗАВИСИМОСТЕЙ И ПАКЕТОВ ===== #\n!pip install --no-cache-dir -qq pip==23.1 &> /dev/null\n!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n!pip install --no-cache-dir -qq faiss-cpu==1.7.3 &> /dev/null\n!apt -y install -qq aria2 &> /dev/null\n\n# ===== УСТАНОВКА НЕОБХОДИМЫХ МОДЕЛЕЙ ===== #\n!python download_files.py \"./assets/\" \"contentvec_base\" &> /dev/null\n\n# ===== УДАЛЕНИЕ НЕНУЖНЫХ ПАПОК ===== #\n!rm -r /content/sample_data\n!rm -r {Train_dir}/.git\n!rm -r {Train_dir}/i18n\n!rm -r {Train_dir}/notebooks\n!rm -r {Train_dir}/tools\n\n# ===== ОЧИСТКА КОНСОЛИ И ВЫВОД КНОПКИ \"Готово\" ===== #\nclear_output()\nButton(description=\"\\u2714 Готово\", button_style=\"success\")","metadata":{"id":"Sb5fzhzEXK8X","cellView":"form","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title <big> ⛏️ **Обработка данных**\n\nTrain_dir = \"/kaggle/working/TrainingModel\"\n\nimport os\nimport re\nimport time\nimport faiss\nimport traceback\nimport numpy as np\nfrom ipywidgets import Button\nfrom multiprocessing import cpu_count\nfrom IPython.display import clear_output\nfrom sklearn.cluster import MiniBatchKMeans\n\n%cd {Train_dir}\nclear_output()\n\n\n# Дайте имя своей модели `(Например - Sanya)`:\nmodel_name = 'Имя датасета'\n\n# Путь к папке с аудио `(датасет)`:\ndataset_folder = '/kaggle/input/Имя датасета'\nif not os.listdir(dataset_folder):\n    raise FileNotFoundError(\"Папка с набором данных пуста!\")\n\n# Частота дискретизации:\nsample_rate = \"40k\"   # 32k, 40k или 48k\nsr = int(sample_rate.rstrip(\"k\")) * 1000\n\n# Метод извлечения тона:\nf0_method = \"rmvpe+\"   # rmvpe+, rmvpe или harvest\n\n# Алгоритм извлечения индекса:\nindex_algorithm = \"Auto\"   # Auto, Faiss или KMeans\n\n\n# ========================================================================== #\n# ДОПОЛНИТЕЛЬНЫЕ ПАРАМЕТРЫ | Скрыты, чтоб незнающие люди ничего не поломали.\n\n# ПРОЦЕНТАЖ | Определяет длину фрагментов / По умолчанию: 3с.700мс.\npercentage = 3.7   # Рекомендуемые значения: 3-5\n\n\n\n!mkdir -p ./logs/{model_name}\nwith open(f'./logs/{model_name}/logfile.log', 'w') as f:\n    # ===== ПРЕДВАРИТЕЛЬНАЯ ПОДГОТОВКА ДАТАСЕТА ===== #\n    !python {Train_dir}/infer/modules/train/preprocess.py {dataset_folder} {sr} 2 ./logs/{model_name} False {percentage}\n    clear_output()\n    # ===== ИЗВЛЕЧЕНИЕ ТОНА ГОЛОСА ===== #\n    !python {Train_dir}/infer/modules/train/extract_f0.py 1 0 0 ./logs/{model_name} False {f0_method}\n    clear_output()\n    # ===== ИЗВЛЕЧЕНИЕ ПРИЗНАКОВ ТОНА ГОЛОСА ===== #\n    !python {Train_dir}/infer/modules/train/extract_feature.py 1 0 ./logs/{model_name} v2 False\nwith open(f'./logs/{model_name}/logfile.log','r') as f:\n    if 'Все признаки извлечены!' in f.read():\n        clear_output()\n    else:\n        raise Exception(\"Ошибка предварительной обработки данных... Убедитесь, что папка с набором данных выбрана правильно.\")\n\n\ndef train_index(model_name, version, index_algorithm):\n    try:\n        exp_dir = f\"logs/{model_name}\"\n        os.makedirs(exp_dir, exist_ok=True)\n\n        feature_dir = f\"{exp_dir}/3_feature256\" if version == \"v1\" else f\"{exp_dir}/3_feature768\"\n\n        index_filename = f\"added_{model_name}_{version}.index\"\n        index_filepath = os.path.join(exp_dir, index_filename)\n\n        if not os.path.exists(feature_dir) or len(os.listdir(feature_dir)) == 0:\n            return \"Пожалуйста, сначала выполните извлечение признаков!\"\n\n        npys = []\n        for name in sorted(os.listdir(feature_dir)):\n            phone = np.load(f\"{feature_dir}/{name}\")\n            npys.append(phone)\n\n        big_npy = np.concatenate(npys, axis=0)\n\n        big_npy_idx = np.arange(big_npy.shape[0])\n        np.random.shuffle(big_npy_idx)\n        big_npy = big_npy[big_npy_idx]\n\n        if big_npy.shape[0] > 2e5 and (index_algorithm == \"Auto\" or index_algorithm == \"KMeans\"):\n            big_npy = (\n                MiniBatchKMeans(\n                    n_clusters=10000,\n                    verbose=True,\n                    batch_size=256 * cpu_count(),\n                    compute_labels=False,\n                    init=\"random\",\n                )\n                .fit(big_npy)\n                .cluster_centers_\n            )\n\n        n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n\n        index_added = faiss.index_factory(256 if version == \"v1\" else 768, f\"IVF{n_ivf},Flat\")\n        index_ivf_added = faiss.extract_index_ivf(index_added)\n        index_ivf_added.nprobe = 1\n        index_added.train(big_npy)\n\n        batch_size_add = 8192\n        for i in range(0, big_npy.shape[0], batch_size_add):\n            index_added.add(big_npy[i : i + batch_size_add])\n\n        faiss.write_index(index_added, index_filepath)\n\n        clear_output()\n        print(f\"Индекс успешно сохранен - '{index_filepath}'\")\n\n    except Exception as error:\n        print(f\"Произошла ошибка при извлечении индекса: {error}\")\n        print(\"Если вы запускаете этот код в виртуальной среде, убедитесь, что у вас достаточно GPU для генерации файла индекса.\")\n\n\ntraining_log = train_index(model_name, \"v2\", index_algorithm)\n\n\n# ================================ #\n# ===== ОПИСАНИЕ ПАРАМЕТРОВ: ===== #\n\n# model_name - Имя вашей модели. Это название будет использоваться для создания папки, где будут храниться все результаты обучения и лог-файлы. Разрешены только английские буквы, цифры и символ подчёркивания (`_`). Пробелы и специальные символы запрещены.\n\n# dataset_folder - Путь к папке, где находятся ваши аудиофайлы (датасет). Убедитесь, что папка содержит аудиофайлы, которые вы хотите использовать для обучения модели RVC. Эти аудиофайлы будут преобразованы в признаки, которые используются для обучения. Рекомендуется использовать не менее 10 минут чистого аудио без шумов или пауз. Рекомендуемые форматы файлов: .wav или .flac.\n\n# sample_rate - Частота дискретизации аудиофайлов. Этот параметр определяет, с какой частотой будут обрабатываться ваши аудиофайлы. Выбор частоты влияет на качество и скорость обработки:\n# * 32k - 32.000 Гц (низкая частота, быстрая обработка, но менее качественный звук).\n# * 40k - 40.000 Гц (стандартный выбор для большинства задач, хорошее соотношение скорости и качества).\n# * 48k - 48.000 Гц (высокая частота, более качественный звук, но требует больше ресурсов).\n\n# f0_method - Метод извлечения тона голоса. Этот параметр определяет, как программа будет определять высоту звука (F0) в ваших аудиофайлах. Выбор метода влияет на точность и скорость обработки:\n# * harvest - Метод, обеспечивающий лучшее воспроизведение тонов, но медленнее и может давать ошибки на начальных этапах. Подходит для акапелл.\n# * rmvpe - Комбинация методов Pm и Crepe, обеспечивающая высокую точность и скорость. Наиболее верный метод для модели голоса.\n# * rmvpe+ - Улучшенная версия Rmvpe, обеспечивающая высокую точность и скорость обработки. Подходит для сложных аудиофайлов.\n\n# index_algorithm - Алгоритм кластеризации данных. Этот параметр определяет, как программа будет группировать данные для обучения модели RVC. Выбор алгоритма зависит от размера вашего датасета:\n# * Auto - Программа автоматически выбирает лучший метод в зависимости от размера вашего датасета. Рекомендуется для большинства случаев.\n# * Faiss - Мощный алгоритм для поиска ближайших соседей, эффективен для больших датасетов. Подходит для сложных и объёмных данных.\n# * KMeans - Простой и быстрый алгоритм кластеризации, который делит данные на группы (кластеры). Подходит для средних и больших датасетов, особенно если вы хотите сэкономить время.\n\n# По поводу ресурсов, которые предоставляет Google Colab, могу сказать следующее: оставьте этот параметр на Auto.\n# Если же вы хотите выбрать между двумя алгоритмами, то:\n# * Faiss — подходит для наборов данных, содержащих менее одного часа информации.\n# * KMeans — рекомендуется для наборов с более чем часовым объёмом данных.\n# Конечно, вы можете попробовать запустить Faiss и на часовом наборе данных, но, думаю, что либо Google Colab не сможет справиться с нагрузкой, либо процесс создания индекса займёт слишком много времени, и вы устанете ждать, либо на колабе закончатся бесплатные ресурсы и вам не хватит времени на тренировку.\n","metadata":{"cellView":"form","id":"c9a4PKyP1yQE","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@title <big>🤖 **Тренировка модели**\n\nTrain_dir = \"/kaggle/working/TrainingModel\"\n\n%cd {Train_dir}\nnow_dir=os.getcwd()\n\nimport json\nimport os\nimport pathlib\nimport traceback\nfrom random import shuffle\nfrom subprocess import PIPE, STDOUT, Popen\nfrom urllib.parse import urlparse\n\nfrom IPython.display import clear_output\n\n# Общее количество эпох для тренировки:\nepochs = \"500\"   # от 1 до бесконечности\n\n# Частота сохранения моделей на диск:\nsave_epoch = \"100\"   # от 5 до 100, но лучше не менять, так как продолжить тренировку нельзя\n\n# Предварительно обученные модели:\npretrain = \"Snowie v3\"   # Default, Snowie v3, TITAN-Medium\n\n# Default - Стандартный претрейн сделанный разработчиками RVC\n# Snowie v3 - Русский претрейн / by MUSTAR\n# TITAN-Medium - Английский претрейн / by Blaise\n\n# Пользовательские предварительно обученные модели:\ncustom_pretrained = False   # True - включено / False - выключено\nd_pretrained_link = \"\"   # Ссылка на D файл\ng_pretrained_link = \"\"   # Ссылка на G файл\n# Cсылки можно взять тут: https://huggingface.co/Politrees/RVC_resources/tree/main/pretrained/v2\n\n# Количество фрагментов датасета, обрабатываемых за один шаг:\nbatch_size = 8   # от 4 до 16\n\n# Экономия памяти при тренировке:\nfp16_run = False   # True - включено / False - выключено\n\n# Включить TensorBoard:\ntensorboard = False   # True - включено / False - выключено\n\n\n# ============================================ #\n# ===== НИЖЕ КОД, ЗАПУСКАЮЩИЙ ТРЕНИРОВКУ ===== #\n\nparam_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\nhugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gin\" + \"gfa\" + \"ce.co\" + \"/Poli\" + \"tree\" + \"s/RV\" + \"C_res\" + \"ourc\" + \"es/re\" + \"solv\" + \"e/ma\" + \"in/pret\" + \"rain\" + \"ed/v2\"\n\npretrain_outpath = \"/content/pretrained_models\"\n!rm -r {pretrain_outpath}  &> /dev/null\n\nclear_output()\nprint(\"Запуск...\")\n\nmodels = {\n    \"Default\": [\n        (f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D.pth\"),\n        (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G.pth\"),\n    ],\n    \"Snowie v3\": [\n        (f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D.pth\"),\n        (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G.pth\"),\n    ],\n    \"TITAN-Medium\": [\n        (f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D.pth\"),\n        (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G.pth\"),\n    ],\n}\n\nif custom_pretrained:\n    if d_pretrained_link and g_pretrained_link:\n        d_filename = os.path.basename(urlparse(d_pretrained_link).path)\n        g_filename = os.path.basename(urlparse(g_pretrained_link).path)\n        G_file = f'{pretrain_outpath}/{g_filename}'\n        D_file = f'{pretrain_outpath}/{d_filename}'\n        print(f\"Установка пользовательских претрейнов...\\nG_file - {g_filename}\\nD_file - {d_filename}\")\n        !aria2c {param_aria} {g_pretrained_link} -d {pretrain_outpath} -o {g_filename} &> /dev/null\n        !aria2c {param_aria} {d_pretrained_link} -d {pretrain_outpath} -o {d_filename} &> /dev/null\n    else:\n        raise ValueError(\"Для custom_pretrained необходимо указать ссылки на D и G файлы претрейна.\")\nelse:\n    print(f\"Установка претрейна {pretrain}...\")\n    for f in models[pretrain]:\n        !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n\n    G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n    D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n\ndef click_train(\n    experiment_dir,\n    sample_rate,\n    use_f0,\n    speaker_id,\n    save_epoch_interval,\n    total_epochs,\n    batch_size,\n    save_latest,\n    pretrained_G,\n    pretrained_D,\n    gpu_ids,\n    cache_gpu,\n    save_every_weights,\n    version,\n):\n    exp_dir = f\"{now_dir}/logs/{experiment_dir}\"\n    os.makedirs(exp_dir, exist_ok=True)\n\n    #data_dir = f\"{exp_dir}/data\"\n    f0_dir = f\"{exp_dir}/2a_f0\"\n    f0nsf_dir = f\"{exp_dir}/2b-f0nsf\"\n    gt_wavs_dir = f\"{exp_dir}/0_gt_wavs\"\n    feature_dir = f\"{exp_dir}/3_feature256\" if version == \"v1\" else f\"{exp_dir}/3_feature768\"\n\n    fea_dim = 256 if version == \"v1\" else 768\n    opt = []\n\n    if use_f0:\n        names = (\n            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n        )\n    else:\n        names = (\n            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n        )\n\n    for name in names:\n        if use_f0:\n            opt.append(\n                f\"{gt_wavs_dir}/{name}.wav|\"\n                f\"{feature_dir}/{name}.npy|\"\n                f\"{f0_dir}/{name}.wav.npy|\"\n                f\"{f0nsf_dir}/{name}.wav.npy|{speaker_id}\"\n            )\n        else:\n            opt.append(\n                f\"{gt_wavs_dir}/{name}.wav|\"\n                f\"{feature_dir}/{name}.npy|{speaker_id}\"\n            )\n\n    if use_f0:\n        for _ in range(2):\n            opt.append(\n                f\"{now_dir}/logs/mute/0_gt_wavs/mute{sample_rate}.wav|\"\n                f\"{now_dir}/logs/mute/3_feature{fea_dim}/mute.npy|\"\n                f\"{now_dir}/logs/mute/2a_f0/mute.wav.npy|\"\n                f\"{now_dir}/logs/mute/2b-f0nsf/mute.wav.npy|{speaker_id}\"\n            )\n    else:\n        for _ in range(2):\n            opt.append(\n                f\"{now_dir}/logs/mute/0_gt_wavs/mute{sample_rate}.wav|\"\n                f\"{now_dir}/logs/mute/3_feature{fea_dim}/mute.npy|{speaker_id}\"\n            )\n\n    shuffle(opt)\n\n    with open(f\"{exp_dir}/filelist.txt\", \"w\") as f:\n        f.write(\"\\n\".join(opt))\n\n    print(\"Запись списка файлов завершена\")\n    print(\"Использование графических процессоров:\", str(gpu_ids))\n\n    if pretrained_G == \"\":\n        print(\"Нет предварительно обученного генератора\")\n    if pretrained_D == \"\":\n        print(\"Без предварительно обученного дискриминатора\")\n\n    if version == \"v1\" or sample_rate == \"40k\":\n        config_path = f\"configs/v1/{sample_rate}.json\"\n    else:\n        config_path = f\"configs/v2/{sample_rate}.json\"\n\n    config_save_path = os.path.join(exp_dir, \"config.json\")\n    if not pathlib.Path(config_save_path).exists():\n        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n            with open(config_path, \"r\") as config_file:\n                config_data = json.load(config_file)\n                config_data[\"train\"][\"fp16_run\"] = fp16_run\n                json.dump(\n                    config_data,\n                    f,\n                    ensure_ascii=False,\n                    indent=4,\n                    sort_keys=True,\n                )\n            f.write(\"\\n\")\n\n    print(\"\\nЗапись файлов завершена\\n\")\n    print(\"Запуск программы...\\n\")\n\n    cmd = (\n        f'python {Train_dir}/infer/modules/train/train.py '\n        f'-e \"{experiment_dir}\" '\n        f'-sr {sample_rate} '\n        f'-f0 {1 if use_f0 else 0} '\n        f'-bs {batch_size} '\n        f'-g {gpu_ids} '\n        f'-te {total_epochs} '\n        f'-se {save_epoch_interval} '\n        f'{\"-pg %s\" % pretrained_G if pretrained_G != \"\" else \"\"} '\n        f'{\"-pd %s\" % pretrained_D if pretrained_D != \"\" else \"\"} '\n        f'-l {1 if save_latest == True else 0} '\n        f'-c {1 if cache_gpu == True else 0} '\n        f'-sw {1 if save_every_weights == True else 0} '\n        f'-v {version}'\n    )\n\n    try:\n        p = Popen(\n            cmd,\n            shell=True,\n            cwd=now_dir,\n            stdout=PIPE,\n            stderr=STDOUT,\n            bufsize=1,\n            universal_newlines=True,\n        )\n\n        for line in p.stdout:\n            print(line.strip())\n\n        p.wait()\n\n    except Exception as e:\n        with open(f\"{exp_dir}/error_log.txt\", \"w\") as f:\n            f.write(\"Произошла ошибка:\\n\")\n            f.write(traceback.format_exc())\n        raise Exception(f\"Произошла ошибка: {e}\")\n\n    return \"Программа закрыта.\"\n\nif tensorboard:\n    %load_ext tensorboard\n    %tensorboard --logdir ./logs --port=8888\nif \"cache\" not in locals():\n    cache = False\ntraining_log = click_train(\n    model_name,\n    sample_rate,\n    True,\n    0,\n    save_epoch,\n    epochs,\n    batch_size,\n    True,\n    G_file,\n    D_file,\n    0,\n    cache,\n    True,\n    'v2',\n)\nprint(training_log)","metadata":{"cellView":"form","id":"WSWzfETu12lS","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport zipfile\nimport glob\n\n# Задайте имя ZIP-архива здесь:\nZIP_NAME = \"Model.zip\"\n\ndef check_and_zip_files(model_name, zip_name=ZIP_NAME):\n    base_name = os.path.splitext(zip_name)[0]  # Убираем расширение .zip\n    \n    # Поиск файла .index с учетом возможного различного числа после IVF\n    index_files = glob.glob(f\"/kaggle/working/TrainVocModel/logs/{model_name}/added_{model_name}_v2.index\")\n    if not index_files:\n        return False\n    index_file_path = index_files[0]\n    index_file_name = os.path.basename(index_file_path).replace(model_name, base_name)\n    \n    pth_file = f\"/kaggle/working/TrainVocModel/assets/weights/{model_name}.pth\"\n    \n    if os.path.exists(index_file_path) and os.path.exists(pth_file):\n        with zipfile.ZipFile(f\"/kaggle/working/{zip_name}\", 'w') as zipf:\n            zipf.write(index_file_path, index_file_name)\n            zipf.write(pth_file, f\"{base_name}.pth\")\n        return True\n    return False\n\n# После завершения тренировки:\nif check_and_zip_files(model_name):\n    print(f\"Файлы модели упакованы в {ZIP_NAME}\")\nelse:\n    print(\"Не удалось найти файлы модели.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## <big>\n---\n    Модель сохраняется на диск автоматически.\n\n    * Путь к .pth файлу:\n    TrainingModel / assets / weights / [имя модели].pth\n    * Примеры:\n    - TrainingModel / assets / weights / my_model.pth\n    - TrainingModel / assets / weights / my_model_e10_s500.pth\n\n    * Путь к .index файлу:\n    TrainingModel / logs / [имя модели] / added_IVF[id]_Flat_nprobe_1_[имя модели]_v2.index\n    * Пример:\n    - TrainingModel / logs / my_model / added_IVF123_Flat_nprobe_1_my_model_v2.index\n---","metadata":{"id":"QW3zegy0fj1G"}}]}
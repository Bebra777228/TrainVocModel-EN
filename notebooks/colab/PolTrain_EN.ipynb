{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bebra777228/TrainVocModel-EN/blob/main/notebooks/colab/PolTrain_EN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center>\n",
        "\n",
        "PolTrain - 18.11.24\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**<font color='#FF8C00'>I will be glad of your support!</font>**\n",
        "\n",
        "<a href=\"https://www.donationalerts.com/r/politrees\" title=\"Go to Donationalerts\">\n",
        "   <img src=\"https://upload.wikimedia.org/wikipedia/ru/a/ad/DA_Logo_Color.svg\" width=\"200\" alt=\"Donationalerts\">\n",
        "</a>\n",
        "\n",
        "**I make models to order. Details in [Telegram](https://t.me/Politrees2)**\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "**Stay up to date with all updates and news! Subscribe to my [Telegram channel](https://t.me/pol1trees)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "r4ihJIzbgfK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< TRAINING**\n",
        "\n",
        "`Model Training | Continue Training Model`"
      ],
      "metadata": {
        "id": "XnIUS5P9VauG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< MODEL TRAINING**"
      ],
      "metadata": {
        "id": "O_27mvQ9mZjQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb5fzhzEXK8X",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title <big>⬇️ **RVC Installation**\n",
        "\n",
        "print(\"Checking GPU availability...\")\n",
        "\n",
        "import os, torch\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nGPU is available!\\n\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"\\nGPU is not available!\\n\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    raise Exception('Unfortunately, you do not have GPU access on your current account. Please switch to another account that has GPU access or wait 24 hours before trying again.')\n",
        "\n",
        "Train_dir = \"/content/drive/MyDrive/TrainingModel\"\n",
        "\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/dataset'):\n",
        "    os.makedirs('/content/dataset')\n",
        "\n",
        "if not os.path.isdir(f'{Train_dir}'):\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone -b PolTrain-Stable https://github.com/Bebra777228/TrainVocModel-EN {Train_dir} &> /dev/null\n",
        "\n",
        "%cd {Train_dir}\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation may take up to 5 minutes. Please wait...\")\n",
        "print(\"\\nFor any questions, write to TG: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install --no-cache-dir -qq pip==23.1 &> /dev/null\n",
        "!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n",
        "!pip install --no-cache-dir -qq faiss-cpu==1.7.3 &> /dev/null\n",
        "!apt -y install -qq aria2 &> /dev/null\n",
        "!python download_files.py &> /dev/null\n",
        "\n",
        "!wget https://raw.githubusercontent.com/Bebra777228/TrainVocModel-EN/refs/heads/main/infer/lib/slicer2_gpu.py -O {Train_dir}/infer/lib/slicer2_gpu.py &> /dev/null\n",
        "!wget https://raw.githubusercontent.com/Bebra777228/TrainVocModel-EN/refs/heads/main/infer/modules/train/preprocess_custom.py -O {Train_dir}/infer/modules/train/preprocess_custom.py &> /dev/null\n",
        "\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Done\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big> ⛏️ **Data Processing**\n",
        "\n",
        "import os, re, faiss, traceback\n",
        "import numpy as np\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Give a name to your model `(For example - Sanya)`:**\n",
        "model_name = '' # @param {\"type\":\"string\",\"placeholder\":\"Give a name to your model\"}\n",
        "if not re.match(r'^[\\w_-]+$', model_name):\n",
        "    raise ValueError(\"Model name contains invalid characters or spaces!\")\n",
        "#@markdown * **Path to the audio folder `(dataset)`:**\n",
        "dataset_folder = '/content/dataset' #@param {type:\"string\"}\n",
        "if not os.listdir(dataset_folder):\n",
        "    raise FileNotFoundError(\"Dataset folder is empty!\")\n",
        "#@markdown ---\n",
        "#@markdown * **Sampling rate:**\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"]\n",
        "sr = int(sample_rate.rstrip(\"k\")) * 1000\n",
        "#@markdown * **Memory saving during dataset processing:**\n",
        "is_half = True # @param {type:\"boolean\"}\n",
        "#@markdown * **Improved data processing (experimental):**\n",
        "new_preprocess = False # @param {type:\"boolean\"}\n",
        "percentage = 3.7\n",
        "#@markdown ---\n",
        "\n",
        "\n",
        "##################################################\n",
        "# Data Processing\n",
        "##################################################\n",
        "\n",
        "if new_preprocess:\n",
        "    preprocess_file = 'preprocess_custom.py'\n",
        "else:\n",
        "    preprocess_file = 'preprocess.py'\n",
        "\n",
        "# Check if preprocess_custom.py file exists if selected\n",
        "if new_preprocess and not os.path.isfile(os.path.join(os.getcwd(), 'infer/modules/train', preprocess_file)):\n",
        "    print(\"\\npreprocess_custom.py file not found.\\nThe standard preprocess.py file will be used.\\n\")\n",
        "    preprocess_file = 'preprocess.py'\n",
        "\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log', 'w') as f:\n",
        "    print(\"Processing dataset...\")\n",
        "!python infer/modules/train/{preprocess_file} {dataset_folder} {sr} 2 ./logs/{model_name} False {percentage}\n",
        "with open(f'./logs/{model_name}/preprocess.log', 'r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "    else:\n",
        "        raise Exception(\"Data preprocessing error... Make sure the dataset folder is selected correctly.\")\n",
        "\n",
        "##################################################\n",
        "# Feature and Characteristic Extraction\n",
        "##################################################\n",
        "\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"Starting processing...\")\n",
        "!python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} {is_half}\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 ./logs/{model_name} v2 {is_half}\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "    else:\n",
        "        raise Exception(\"Data preprocessing error... Make sure the dataset folder is selected correctly.\")\n",
        "\n",
        "##################################################\n",
        "# Training Index\n",
        "##################################################\n",
        "\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"Please perform feature extraction first!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"Please perform feature extraction first!\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"Attempting kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=10000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * cpu_count(),\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            print(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"Training index...\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"Saving...\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"index successfully built, added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if 'Saving...' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Done\", button_style=\"success\"))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "c9a4PKyP1yQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🤖 **Model Training**\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "from random import shuffle\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from IPython.display import clear_output\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "now_dir=os.getcwd()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Total number of epochs for training:** `(Recommended 500-1000)`\n",
        "epochs = \"500\" # @param {type:\"string\"}\n",
        "#@markdown * **Model saving frequency to disk:** `(Recommended 5-50)`\n",
        "save_epoch = \"50\" # @param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown * **Pre-trained models:**\n",
        "pretrain = \"* Default —> (Sampling — ALL)\" # @param [\"* Default —> (Sampling — ALL)\", \"\", \"RUSSIAN PRETRAINED:\", \"* Snowie —> (Sampling — 40k)\", \"* Snowie v2 —> (Sampling — 40k and 48k)\", \"* Snowie v3 —> (Sampling — ALL)\", \"\", \"ENGLISH PRETRAINED:\", \"* Ov2Super —> (Sampling — 40k)\", \"* RIN_E3 —> (Sampling — 40k)\", \"* TITAN-Medium —> (Sampling — ALL)\", \"\", \"HYBRIDS:\", \"* Snowie + RIN_E3 —> (Sampling — 40k)\", \"\", \"MULTILINGUAL:\", \"* Rigel —> (Sampling — 32k)\"]\n",
        "#@markdown * **Custom pre-trained models:**\n",
        "custom_pretrained = False # @param {type:\"boolean\"}\n",
        "d_pretrained_link = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Link to D file\"}\n",
        "g_pretrained_link = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Link to G file\"}\n",
        "#@markdown > You can get links here: [HuggingFace](https://huggingface.co/Politrees/RVC_resources/tree/main/pretrained/v2)\n",
        "#@markdown ---\n",
        "#@markdown * **Number of dataset segments processed per step:**\n",
        "batch_size = 8  # @param {type:\"slider\", min:4, max:32, step:4}\n",
        "#@markdown * **Memory saving during training:**\n",
        "fp16_run = True # @param {type:\"boolean\"}\n",
        "#@markdown * **Enable TensorBoard:**\n",
        "tensorboard = True # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "print(\"Starting...\")\n",
        "\n",
        "param_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\n",
        "hugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gin\" + \"gfa\" + \"ce.co\" + \"/Poli\" + \"tree\" + \"s/RV\" + \"C_res\" + \"ourc\" + \"es/re\" + \"solv\" + \"e/ma\" + \"in/pret\" + \"rain\" + \"ed/v2\"\n",
        "pretrain_outpath = \"/content/pretrained_models\"\n",
        "\n",
        "!rm -r /content/pretrained_models  &> /dev/null\n",
        "clear_output()\n",
        "\n",
        "models = {\n",
        "    \"* Default —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D.pth\"),\n",
        "        (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Snowie/D_Snowie_40k.pth\", f\"Snowie_D.pth\"),\n",
        "        (f\"40k/Snowie/G_Snowie_40k.pth\", f\"Snowie_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie v2 —> (Sampling — 40k and 48k)\": [\n",
        "        (f\"{sample_rate}/Snowie/D_SnowieV2_{sample_rate}.pth\", f\"SnowieV2_D.pth\"),\n",
        "        (f\"{sample_rate}/Snowie/G_SnowieV2_{sample_rate}.pth\", f\"SnowieV2_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie v3 —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D.pth\"),\n",
        "        (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G.pth\"),\n",
        "    ],\n",
        "    \"* Ov2Super —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Ov2/f0Ov2Super40kD.pth\", f\"Ov2Super_D.pth\"),\n",
        "        (f\"40k/Ov2/f0Ov2Super40kG.pth\", f\"Ov2Super_G.pth\"),\n",
        "    ],\n",
        "    \"* RIN_E3 —> (Sampling — 40k)\": [\n",
        "        (f\"40k/RIN_E/D_RIN_E3.pth\", f\"RinE3_D.pth\"),\n",
        "        (f\"40k/RIN_E/G_RIN_E3.pth\", f\"RinE3_G.pth\"),\n",
        "    ],\n",
        "    \"* TITAN-Medium —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D.pth\"),\n",
        "        (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie + RIN_E3 —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Snowie/D_Snowie-X-Rin_40k.pth\", f\"SnowieV3_x_RinE3_D.pth\"),\n",
        "        (f\"40k/Snowie/G_Snowie-X-Rin_40k.pth\", f\"SnowieV3_x_RinE3_G.pth\"),\n",
        "    ],\n",
        "    \"* Rigel —> (Sampling — 32k)\": [\n",
        "        (f\"32k/Rigel/D_Rigel_32k.pth\", f\"Rigel_D.pth\"),\n",
        "        (f\"32k/Rigel/G_Rigel_32k.pth\", f\"Rigel_G.pth\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "if custom_pretrained:\n",
        "    if d_pretrained_link and g_pretrained_link:\n",
        "        d_filename = os.path.basename(urlparse(d_pretrained_link).path)\n",
        "        g_filename = os.path.basename(urlparse(g_pretrained_link).path)\n",
        "        G_file = f'{pretrain_outpath}/{g_filename}'\n",
        "        D_file = f'{pretrain_outpath}/{d_filename}'\n",
        "        print(f\"Installing custom pre-trains...\\nG_file - {g_filename}\\nD_file - {d_filename}\")\n",
        "        !aria2c {param_aria} {g_pretrained_link} -d {pretrain_outpath} -o {g_filename} &> /dev/null\n",
        "        !aria2c {param_aria} {d_pretrained_link} -d {pretrain_outpath} -o {d_filename} &> /dev/null\n",
        "    else:\n",
        "        raise ValueError(\"For custom_pretrained, you need to specify links to D and G pre-train files.\")\n",
        "else:\n",
        "    print(f\"Installing pre-train {pretrain}...\")\n",
        "    for f in models[pretrain]:\n",
        "        !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n",
        "\n",
        "    G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n",
        "    D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    print(\"File list writing completed\")\n",
        "    print(\"Using GPUs:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pre-trained generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pre-trained discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = f\"configs/v1/{sr2}.json\"\n",
        "    else:\n",
        "        config_path = f\"configs/v2/{sr2}.json\"\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                config_data[\"train\"][\"fp16_run\"] = fp16_run\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"\\nFile writing completed\\n\")\n",
        "    print(\"Starting program...\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        f'python infer/modules/train/train.py -e \"{exp_dir1}\" -sr {sr2} -f0 {1 if if_f0_3 else 0} -bs {batch_size12} -g {gpus16} -te {total_epoch11} -se {save_epoch10} {\"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\"} {\"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\"} -l {1 if if_save_latest13 == True else 0} -c {1 if if_cache_gpu17 == True else 0} -sw {1 if if_save_every_weights18 == True else 0} -v {version19}'\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "        for line in p.stdout:\n",
        "            print(line.strip())\n",
        "\n",
        "        p.wait()\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"An error occurred: {e}\")\n",
        "\n",
        "    return \"Program closed.\"\n",
        "\n",
        "if tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs --port=8888\n",
        "if \"cache\" not in locals():\n",
        "    cache = False\n",
        "training_log = click_train(\n",
        "    model_name,\n",
        "    sample_rate,\n",
        "    True,\n",
        "    0,\n",
        "    save_epoch,\n",
        "    epochs,\n",
        "    batch_size,\n",
        "    True,\n",
        "    G_file,\n",
        "    D_file,\n",
        "    0,\n",
        "    cache,\n",
        "    True,\n",
        "    'v2',\n",
        ")\n",
        "print(training_log)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WSWzfETu12lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< CONTINUE MODEL TRAINING**"
      ],
      "metadata": {
        "id": "8q3V33sNvi6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>⬇️ **RVC Installation**\n",
        "\n",
        "print(\"Checking GPU availability...\")\n",
        "\n",
        "import os, torch\n",
        "from ipywidgets import Button\n",
        "from IPython.display import clear_output\n",
        "from google.colab import drive\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"\\nGPU is available!\\n\")\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    print(\"\\nGPU is not available!\\n\")\n",
        "    device = torch.device(\"cpu\")\n",
        "    raise Exception('Unfortunately, you do not have GPU access on your current account. Please switch to another account that has GPU access or wait 24 hours before trying again.')\n",
        "\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.isdir('/content/drive/MyDrive/TrainingModel'):\n",
        "    raise Exception(\"TrainingModel folder not found. Continuing model training is not possible without the model itself.\")\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation may take up to 5 minutes. Please wait...\")\n",
        "print(\"\\nFor any questions, write to TG: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install --no-cache-dir -qq pip==23.1 &> /dev/null\n",
        "!pip install --no-cache-dir -qq -r requirements.txt &> /dev/null\n",
        "!pip install --no-cache-dir -qq faiss-cpu==1.7.3 &> /dev/null\n",
        "!apt -y install -qq aria2 &> /dev/null\n",
        "\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Done\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "ZqVvS-d-btU5",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🤖 **Model Training**\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import pathlib\n",
        "from random import shuffle\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from IPython.display import clear_output\n",
        "\n",
        "now_dir=os.getcwd()\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Enter your model name:**\n",
        "model_name = '' # @param {\"type\":\"string\",\"placeholder\":\"Enter your model name\"}\n",
        "#@markdown * **Sampling rate:**\n",
        "sample_rate = \"40k\"  # @param [\"32k\", \"40k\", \"48k\"]\n",
        "#@markdown ---\n",
        "#@markdown * **Total number of epochs for training:** `(Recommended 500-1000)`\n",
        "epochs = \"1000\" # @param {type:\"string\"}\n",
        "#@markdown * **Model saving frequency to disk:** `(Recommended 5-50)`\n",
        "save_epoch = \"50\" # @param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown * **Pre-trained models:**\n",
        "pretrain = \"* Default —> (Sampling — ALL)\" # @param [\"* Default —> (Sampling — ALL)\", \"\", \"RUSSIAN PRETRAINED:\", \"* Snowie —> (Sampling — 40k)\", \"* Snowie v2 —> (Sampling — 40k and 48k)\", \"* Snowie v3 —> (Sampling — ALL)\", \"\", \"ENGLISH PRETRAINED:\", \"* Ov2Super —> (Sampling — 40k)\", \"* RIN_E3 —> (Sampling — 40k)\", \"* TITAN-Medium —> (Sampling — ALL)\", \"\", \"HYBRIDS:\", \"* Snowie + RIN_E3 —> (Sampling — 40k)\", \"\", \"MULTILINGUAL:\", \"* Rigel —> (Sampling — 32k)\"]\n",
        "#@markdown * **Custom pre-trained models:**\n",
        "custom_pretrained = False # @param {type:\"boolean\"}\n",
        "d_pretrained_link = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Link to D file\"}\n",
        "g_pretrained_link = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Link to G file\"}\n",
        "#@markdown > You can get links here: [HuggingFace](https://huggingface.co/Politrees/RVC_resources/tree/main/pretrained/v2)\n",
        "#@markdown ---\n",
        "#@markdown * **Number of dataset segments processed per step:**\n",
        "batch_size = 8  # @param {type:\"slider\", min:4, max:32, step:4}\n",
        "#@markdown * **Enable TensorBoard:**\n",
        "tensorboard = True # @param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "\n",
        "print(\"Starting...\")\n",
        "\n",
        "param_aria = \"--con\" + \"sole-l\" + \"og-le\" + \"vel=er\" + \"ror -c -x 1\" + \"6 -s 1\" + \"6 -k 1\" + \"M\"\n",
        "hugg_pret = \"ht\" + \"tps:/\" + \"/hug\" + \"gin\" + \"gfa\" + \"ce.co\" + \"/Poli\" + \"tree\" + \"s/RV\" + \"C_res\" + \"ourc\" + \"es/re\" + \"solv\" + \"e/ma\" + \"in/pret\" + \"rain\" + \"ed/v2\"\n",
        "pretrain_outpath = \"/content/pretrained_models\"\n",
        "\n",
        "!rm -r /content/pretrained_models  &> /dev/null\n",
        "clear_output()\n",
        "\n",
        "models = {\n",
        "    \"* Default —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/Default/f0D{sample_rate}.pth\", f\"default_D.pth\"),\n",
        "        (f\"{sample_rate}/Default/f0G{sample_rate}.pth\", f\"default_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Snowie/D_Snowie_40k.pth\", f\"Snowie_D.pth\"),\n",
        "        (f\"40k/Snowie/G_Snowie_40k.pth\", f\"Snowie_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie v2 —> (Sampling — 40k and 48k)\": [\n",
        "        (f\"{sample_rate}/Snowie/D_SnowieV2_{sample_rate}.pth\", f\"SnowieV2_D.pth\"),\n",
        "        (f\"{sample_rate}/Snowie/G_SnowieV2_{sample_rate}.pth\", f\"SnowieV2_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie v3 —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/Snowie/D_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_D.pth\"),\n",
        "        (f\"{sample_rate}/Snowie/G_SnowieV3.1_{sample_rate}.pth\", f\"SnowieV3_G.pth\"),\n",
        "    ],\n",
        "    \"* Ov2Super —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Ov2/f0Ov2Super40kD.pth\", f\"Ov2Super_D.pth\"),\n",
        "        (f\"40k/Ov2/f0Ov2Super40kG.pth\", f\"Ov2Super_G.pth\"),\n",
        "    ],\n",
        "    \"* RIN_E3 —> (Sampling — 40k)\": [\n",
        "        (f\"40k/RIN_E/D_RIN_E3.pth\", f\"RinE3_D.pth\"),\n",
        "        (f\"40k/RIN_E/G_RIN_E3.pth\", f\"RinE3_G.pth\"),\n",
        "    ],\n",
        "    \"* TITAN-Medium —> (Sampling — ALL)\": [\n",
        "        (f\"{sample_rate}/TITAN/D-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_D.pth\"),\n",
        "        (f\"{sample_rate}/TITAN/G-f0{sample_rate}-TITAN-Medium.pth\", f\"TITAN_Medium_G.pth\"),\n",
        "    ],\n",
        "    \"* Snowie + RIN_E3 —> (Sampling — 40k)\": [\n",
        "        (f\"40k/Snowie/D_Snowie-X-Rin_40k.pth\", f\"SnowieV3_x_RinE3_D.pth\"),\n",
        "        (f\"40k/Snowie/G_Snowie-X-Rin_40k.pth\", f\"SnowieV3_x_RinE3_G.pth\"),\n",
        "    ],\n",
        "    \"* Rigel —> (Sampling — 32k)\": [\n",
        "        (f\"32k/Rigel/D_Rigel_32k.pth\", f\"Rigel_D.pth\"),\n",
        "        (f\"32k/Rigel/G_Rigel_32k.pth\", f\"Rigel_G.pth\"),\n",
        "    ],\n",
        "}\n",
        "\n",
        "if custom_pretrained:\n",
        "    if d_pretrained_link and g_pretrained_link:\n",
        "        d_filename = os.path.basename(urlparse(d_pretrained_link).path)\n",
        "        g_filename = os.path.basename(urlparse(g_pretrained_link).path)\n",
        "        G_file = f'{pretrain_outpath}/{g_filename}'\n",
        "        D_file = f'{pretrain_outpath}/{d_filename}'\n",
        "        print(f\"Installing custom pre-trains...\\nG_file - {g_filename}\\nD_file - {d_filename}\")\n",
        "        !aria2c {param_aria} {g_pretrained_link} -d {pretrain_outpath} -o {g_filename} &> /dev/null\n",
        "        !aria2c {param_aria} {d_pretrained_link} -d {pretrain_outpath} -o {d_filename} &> /dev/null\n",
        "    else:\n",
        "        raise ValueError(\"For custom_pretrained, you need to specify links to D and G pre-train files.\")\n",
        "else:\n",
        "    print(f\"Installing pre-train {pretrain}...\")\n",
        "    for f in models[pretrain]:\n",
        "        !aria2c {param_aria} {hugg_pret}/{f[0]} -d {pretrain_outpath} -o {f[1]} &> /dev/null\n",
        "\n",
        "    G_file = f'{pretrain_outpath}/{models[pretrain][1][1]}'\n",
        "    D_file = f'{pretrain_outpath}/{models[pretrain][0][1]}'\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    print(\"File list writing completed\")\n",
        "    print(\"Using GPUs:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pre-trained generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pre-trained discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = f\"configs/v1/{sr2}.json\"\n",
        "    else:\n",
        "        config_path = f\"configs/v2/{sr2}.json\"\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    print(\"\\nFile writing completed\\n\")\n",
        "    print(\"Starting program...\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        f'python infer/modules/train/train.py -e \"{exp_dir1}\" -sr {sr2} -f0 {1 if if_f0_3 else 0} -bs {batch_size12} -g {gpus16} -te {total_epoch11} -se {save_epoch10} {\"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\"} {\"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\"} -l {1 if if_save_latest13 == True else 0} -c {1 if if_cache_gpu17 == True else 0} -sw {1 if if_save_every_weights18 == True else 0} -v {version19}'\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "        for line in p.stdout:\n",
        "            print(line.strip())\n",
        "\n",
        "        p.wait()\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"An error occurred: {e}\")\n",
        "\n",
        "    return \"Program closed.\"\n",
        "\n",
        "if tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs --port=8888\n",
        "if \"cache\" not in locals():\n",
        "    cache = False\n",
        "training_log = click_train(\n",
        "    model_name,\n",
        "    sample_rate,\n",
        "    True,\n",
        "    0,\n",
        "    save_epoch,\n",
        "    epochs,\n",
        "    batch_size,\n",
        "    True,\n",
        "    G_file,\n",
        "    D_file,\n",
        "    0,\n",
        "    cache,\n",
        "    True,\n",
        "    'v2',\n",
        ")\n",
        "print(training_log)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NkqXOy7G2Pbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <big>\n",
        "---\n",
        "    The model is saved to disk automatically.\n",
        "\n",
        "    * Path to .pth file:\n",
        "    TrainingModel / assets / weights / [model name].pth\n",
        "    * Examples:\n",
        "    - TrainingModel / assets / weights / my_model.pth\n",
        "    - TrainingModel / assets / weights / my_model_e10_s500.pth\n",
        "\n",
        "    * Path to .index file:\n",
        "    TrainingModel / logs / [model name] / added_IVF[id]_Flat_nprobe_1_[model name]_v2.index\n",
        "    * Example:\n",
        "    - TrainingModel / logs / my_model / added_IVF123_Flat_nprobe_1_my_model_v2.index\n",
        "---"
      ],
      "metadata": {
        "id": "QW3zegy0fj1G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='#FF8C00'> **<big> <<< CLI**\n",
        "\n",
        "`Model Check | Convert One Voice to Another | Text to Speech Conversion`"
      ],
      "metadata": {
        "id": "h76D42owRGmD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< MODEL CHECK**"
      ],
      "metadata": {
        "id": "fZ3Kl6DJmtSF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>⬇️ **INSTALLATION**\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import os, torch\n",
        "\n",
        "# Check GPU connection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available!\")\n",
        "    raise Exception('Unfortunately, you do not have GPU access on your current account. Please switch to another account that has GPU access or wait 24 hours before trying again.')\n",
        "\n",
        "# Connect to drive\n",
        "if not os.path.isdir('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation may take up to 5 minutes. Please wait...\")\n",
        "print(\"\\nFor any questions, write to TG: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "# Install dependencies\n",
        "!pip install pip==23.1 &> /dev/null\n",
        "!apt install ffmpeg &> /dev/null\n",
        "!pip install --no-cache-dir -qq python-dotenv torchcrepe fairseq pyworld praat-parselmouth ffmpeg-python faiss-cpu av &> /dev/null\n",
        "\n",
        "# Create and delete folders\n",
        "!mkdir -p /content/input\n",
        "!mkdir -p /content/output\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Done\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "28_80Dwvb7ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🔊 **Upload Vocal File**\n",
        "\n",
        "#@markdown You can upload your file manually to the <big> **`input`** folder\n",
        "\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "\n",
        "# Constants\n",
        "INPUT_DIR = \"/content/input\"\n",
        "VOCAL_FILE_NAME = \"vocal\"\n",
        "ALLOWED_EXTENSIONS = {'.mp3', '.wav'}\n",
        "\n",
        "os.chdir(INPUT_DIR)\n",
        "!rm -r /content/input/*\n",
        "\n",
        "# Upload vocal file\n",
        "audio = files.upload()\n",
        "clear_output()\n",
        "\n",
        "if not audio:\n",
        "    print(\"No file uploaded.\")\n",
        "\n",
        "# Check file extension\n",
        "ext = os.path.splitext(list(audio.keys())[-1])[-1].lower()\n",
        "if ext not in ALLOWED_EXTENSIONS:\n",
        "    !rm -r /content/input/*\n",
        "    print(f\"Invalid file format '{ext}'. Only files with formats {', '.join(ALLOWED_EXTENSIONS)} are allowed.\")\n",
        "    print(\"If you want to upload a file with another format, please upload it manually to the input folder.\")\n",
        "\n",
        "# Rename uploaded file\n",
        "input_audio = VOCAL_FILE_NAME + ext\n",
        "os.rename(list(audio.keys())[-1], input_audio)\n",
        "\n",
        "clear_output()\n",
        "print(f\"File successfully uploaded.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ejdaR2mX1CLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🗣️ **Voice Replacement**\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import IPython.display as ipd\n",
        "from IPython.display import clear_output, display, Audio\n",
        "from google.colab import files\n",
        "from ipywidgets import Button\n",
        "\n",
        "%cd /content/drive/MyDrive/TrainingModel\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Enter your model name:**\n",
        "model_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Model_Name\"}\n",
        "#@markdown * **Enter your model's .pth file name:**\n",
        "pth_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Model_Name_e120_s5280\"}\n",
        "#@markdown <details>\n",
        "#@markdown <summary>Where to find the .pth file?</summary>\n",
        "#@markdown Go to Google Drive and navigate to the path <b>TrainingModel/assets/weights/</b>. Here you will see many files. It is best to choose the file with the largest value of \"<b>_e[number]_s[number]</b>\", or the model without \"<b>_e[number]_s[number]</b>\".\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Voice pitch ( `-24` Male voice || Female voice `24` ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-24, max:24, step:1}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Additional settings:**\n",
        "index_rate = 0 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown <details>\n",
        "#@markdown <summary>Description of <b>index_rate</b></summary>\n",
        "#@markdown Controls the degree of influence of the index file on the analysis result. A higher value increases the influence of the index file, but may amplify artifacts in the audio. Choosing a lower value may help reduce artifacts.\n",
        "protect = 0.33 #@param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "#@markdown <details>\n",
        "#@markdown <summary>Description of <b>protect</b></summary>\n",
        "#@markdown Controls the degree of protection of individual consonants and breath sounds from electroacoustic breaks and other artifacts. The maximum value of 0.5 provides the greatest protection, but may increase the indexing effect, which can negatively affect sound quality. Reducing the value may decrease the degree of protection, but reduce the indexing effect.\n",
        "filter_radius = 3 #@param {type:\"slider\", min:0, max:7, step:1}\n",
        "#@markdown <details>\n",
        "#@markdown <summary>Description of <b>filter_radius</b></summary>\n",
        "#@markdown Controls the radius of filtering the results of tone analysis. If the filtering value is equal to or exceeds 3, median filtering is applied to reduce breath noise.\n",
        "\n",
        "#@markdown * **Output file format:**\n",
        "format = \"mp3\" #@param [\"mp3\", \"wav\", \"flac\"] {allow-input: false}\n",
        "\n",
        "input_path = '/content/input/*.*'\n",
        "model_path = f'{pth_name}.pth'\n",
        "index_path = f'logs/{model_name}/added_*.index'\n",
        "opt_path = f'/content/output/output.{format}'\n",
        "\n",
        "# Delete the previous generated audio file before generating a new one\n",
        "!rm -r /content/output/*\n",
        "\n",
        "# Script to replace voice\n",
        "!python tools/infer_cli.py --f0up_key $pitch --input_path $input_path --index_path $index_path --f0method \"rmvpe\" --opt_path $opt_path --model_name $model_path --index_rate $index_rate --device cuda --is_half False --filter_radius $filter_radius --resample_sr 0 --rms_mix_rate 1 --protect $protect\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > **If you encountered an error or a non-working player, please check the `show_error` checkbox below. Then send a screenshot of the entire window to TG: https://t.me/+GMTP7hZqY0E4OGRi**\n",
        "show_error = False #@param {type:\"boolean\"}\n",
        "if not show_error:\n",
        "    ipd.clear_output()\n",
        "\n",
        "# Display the generated audio file and create a \"Download\" button\n",
        "def download_file(file_path):\n",
        "    files.download(file_path)\n",
        "\n",
        "print(\"\\nGoogle Colab sometimes cannot output the audio window, so:\\n\")\n",
        "print(\"\\n1. First, we output the 'Download' button, after clicking on which you can save the audio recording on your device.\\n\")\n",
        "\n",
        "download_button = Button(description=\"Download\")\n",
        "display(download_button)\n",
        "download_button.on_click(lambda _: download_file(opt_path))\n",
        "\n",
        "print(\"\\n2. Then, we output the audio recording for listening directly in Google Colab.\\n\")\n",
        "print(\"\\nIf you did not see the player or there was a Colab restart, but there are no errors, just wait.\\nOr go to files, open the output folder and download your generated file.\\n\")\n",
        "\n",
        "display(Audio(f\"{opt_path}\", rate=44100))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "O9kgzXqI-sgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< VOICE CONVERSION**"
      ],
      "metadata": {
        "id": "hS9N_NgbghFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🚀 **INSTALLATION**\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import torch\n",
        "\n",
        "# Check GPU connection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available!\")\n",
        "    raise Exception('Unfortunately, you do not have GPU access on your current account. Please switch to another account that has GPU access or wait 24 hours before trying again.')\n",
        "\n",
        "\n",
        "git = \"--de\" + \"pt\" + \"h 1 \" + \"ht\" + \"tp\" + \"s:/\" + \"/gi\" + \"thu\" + \"b.c\" + \"om/Be\" + \"bra7\" + \"772\" + \"28/Po\" + \"lGe\" + \"n-RV\" + \"C\"\n",
        "version = \"--br\" + \"anc\" + \"h \" + \"v1.2.0-fix\" + \" --si\" + \"ngl\" + \"e-br\" + \"an\" + \"ch\"\n",
        "dir = \"/co\" + \"nte\" + \"nt/P\" + \"olG\" + \"en\"\n",
        "\n",
        "# Clone repository\n",
        "!git clone $git $version $dir &> /dev/null\n",
        "%cd $dir\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation may take up to 5 minutes. Please wait...\")\n",
        "print(\"\\nFor any questions, write to TG: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install pip==23.1 &> /dev/null\n",
        "!pip install -qq -r requirements.txt &> /dev/null\n",
        "!python download_models.py &> /dev/null\n",
        "\n",
        "!mkdir -p /content/input\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Done!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8iG9b05oHCbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🔎 **Download Model**\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gdown\n",
        "import requests\n",
        "from mega import Mega\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "rvc_models_dir = '/content/PolGen/models'\n",
        "\n",
        "# Function to unzip zip file\n",
        "def extract_zip(extraction_folder, zip_name):\n",
        "    os.makedirs(extraction_folder, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_folder)\n",
        "    os.remove(zip_name)\n",
        "\n",
        "    index_filepath, model_filepath = None, None\n",
        "    for root, _, files in os.walk(extraction_folder):\n",
        "        for name in files:\n",
        "            if name.endswith('.index') and os.stat(os.path.join(root, name)).st_size > 1024 * 100:\n",
        "                index_filepath = os.path.join(root, name)\n",
        "            if name.endswith('.pth') and os.stat(os.path.join(root, name)).st_size > 1024 * 1024 * 40:\n",
        "                model_filepath = os.path.join(root, name)\n",
        "\n",
        "    if not model_filepath:\n",
        "        raise Exception(f'No .pth model file found in the unzipped zip file. Please check {extraction_folder}.')\n",
        "\n",
        "    os.rename(model_filepath, os.path.join(extraction_folder, os.path.basename(model_filepath)))\n",
        "    if index_filepath:\n",
        "        os.rename(index_filepath, os.path.join(extraction_folder, os.path.basename(index_filepath)))\n",
        "\n",
        "    for filepath in os.listdir(extraction_folder):\n",
        "        if os.path.isdir(os.path.join(extraction_folder, filepath)):\n",
        "            shutil.rmtree(os.path.join(extraction_folder, filepath))\n",
        "\n",
        "# Function to download from URL\n",
        "def download_from_url(url, dir_name):\n",
        "    try:\n",
        "        print(f'[~] Downloading voice model named {dir_name}...')\n",
        "        zip_name = os.path.join(rvc_models_dir, dir_name + '.zip')\n",
        "        extraction_folder = os.path.join(rvc_models_dir, dir_name)\n",
        "        if os.path.exists(extraction_folder):\n",
        "            raise Exception(f'Voice model directory {dir_name} already exists! Choose another name for your voice model.')\n",
        "\n",
        "        if 'drive.google.com' in url:\n",
        "            print('[~] Downloading model from Google Drive...')\n",
        "            file_id = url.split(\"file/d/\")[1].split(\"/\")[0] if \"file/d/\" in url else url.split(\"id=\")[1].split(\"&\")[0]\n",
        "            output = zip_name\n",
        "            gdown.download(id=file_id, output=output, quiet=False)\n",
        "\n",
        "        elif 'huggingface.co' in url:\n",
        "            print('[~] Downloading model from HuggingFace...')\n",
        "            urllib.request.urlretrieve(url, zip_name)\n",
        "\n",
        "        elif 'pixeldrain.com' in url:\n",
        "            print('[~] Downloading model from Pixeldrain...')\n",
        "            file_id = url.split(\"pixeldrain.com/u/\")[1]\n",
        "            response = requests.get(f\"https://pixeldrain.com/api/file/{file_id}\")\n",
        "            with open(zip_name, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "        elif 'mega.nz' in url:\n",
        "            print('[~] Downloading model from Mega...')\n",
        "            m = Mega()\n",
        "            m.download_url(url, dest_filename=zip_name)\n",
        "\n",
        "        elif 'yadi.sk' in url or 'disk.yandex.ru' in url:\n",
        "            print('[~] Downloading model from Yandex Disk...')\n",
        "            yandex_api_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key={}\".format(url)\n",
        "            response = requests.get(yandex_api_url)\n",
        "            if response.status_code == 200:\n",
        "                download_link = response.json().get('href')\n",
        "                urllib.request.url.retrieve(download_link, zip_name)\n",
        "            else:\n",
        "                raise Exception(f\"Error getting download link from Yandex Disk: {response.status_code}\")\n",
        "\n",
        "        print('[~] Unzipping zip file...')\n",
        "        extract_zip(extraction_folder, zip_name)\n",
        "        return f'[+] Model {dir_name} successfully downloaded!'\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))\n",
        "\n",
        "# Function to display list of downloaded models\n",
        "def list_installed_models():\n",
        "    print(\"\\033[1;32m\\nInstalled models:\\n\\033[0m\")\n",
        "    models = [d for d in os.listdir(rvc_models_dir) if os.path.isdir(os.path.join(rvc_models_dir, d))]\n",
        "    for model in models:\n",
        "        print(\"\\033[1;92m\", model, \"\\033[0m\")\n",
        "    print('\\nCopy the model name and paste it into the \"model_name\" field.')\n",
        "\n",
        "# Create widgets with correct sizes\n",
        "url_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the zip file URL',\n",
        "    description='URL:',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "\n",
        "dir_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the model directory name',\n",
        "    description='Model Name:',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "\n",
        "output = widgets.Output(layout=widgets.Layout(width='50%'))\n",
        "\n",
        "def on_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        url = url_input.value\n",
        "        dir_name = dir_name_input.value\n",
        "        try:\n",
        "            result = download_from_url(url, dir_name)\n",
        "            print(result)\n",
        "            clear_output()\n",
        "            list_installed_models()\n",
        "        except Exception as e:\n",
        "            raise Exception(f'Error: {e}')\n",
        "\n",
        "download_button = widgets.Button(\n",
        "    description='Download and Unzip',\n",
        "    disabled=False,\n",
        "    button_style='',\n",
        "    tooltip='Click to download and unzip the model',\n",
        "    icon='download',\n",
        "    layout=widgets.Layout(width='30%', height='50px')\n",
        ")\n",
        "\n",
        "download_button.on_click(on_button_click)\n",
        "\n",
        "# Display widgets\n",
        "display(url_input)\n",
        "display(dir_name_input)\n",
        "display(download_button)\n",
        "display(output)\n"
      ],
      "metadata": {
        "id": "loDUWLJvHIOy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🗣️ **Voice Replacement**\n",
        "\n",
        "import os, subprocess\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "%cd /content/PolGen\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown > **Don't forget to upload your audio file to the input folder.**\n",
        "#@markdown ---\n",
        "#@markdown * **Enter your model name:**\n",
        "model_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter the model name you gave when downloading\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Voice pitch ( `-24` Male voice || Female voice `24` ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-24, max:24, step:1}\n",
        "#@markdown * **Pitch extraction method:**\n",
        "method = \"rmvpe+\"  # @param [\"rmvpe+\", \"rmvpe\", \"mangio-crepe\", \"fcpe\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Additional settings:**\n",
        "index_rate = 0  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "filter_radius = 3  # @param {type:\"slider\", min:0, max:7, step:1}\n",
        "rms = 0.25  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "protect = 0.33  # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "f0_min = 50  # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "f0_max = 1100  # @param {type:\"slider\", min:400, max:16000, step:10}\n",
        "#@markdown <details>\n",
        "#@markdown <summary><b><u>SETTINGS DESCRIPTION</u></b></summary>\n",
        "#@markdown\n",
        "#@markdown > * <b><u>index_rate</u></b> - Controls the degree of influence of the index file on the analysis result. A higher value increases the influence of the index file, but may amplify artifacts in the audio. Choosing a lower value may help reduce artifacts.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>filter_radius</u></b> - Controls the radius of filtering the results of tone analysis. If the filtering value is equal to or exceeds 3, median filtering is applied to reduce breath noise.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>rms</u></b> - Controls the degree of mixing the output signal with its volume envelope. A value close to 1 increases the use of the volume envelope of the output signal, which can improve sound quality.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>protect</u></b> - Controls the degree of protection of individual consonants and breath sounds from electroacoustic breaks and other artifacts. The maximum value of 0.5 provides the greatest protection, but may increase the indexing effect, which can negatively affect sound quality. Reducing the value may decrease the degree of protection, but reduce the indexing effect.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>f0_min</u></b> - Define the lower bound of the pitch range that the algorithm will use to determine the fundamental frequency (F0) in the audio signal.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>f0_min</u></b> - Define the upper bound of the pitch range that the algorithm will use to determine the fundamental frequency (F0) in the audio signal.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Output file format:**\n",
        "format = \"mp3\"  # @param [\"mp3\", \"wav\", \"flac\"]\n",
        "#@markdown ---\n",
        "\n",
        "input_path = \"/content/input/*.*\"\n",
        "error_file = \"/content/error.log\"\n",
        "opt_path = f\"/content/PolGen/output/Voice_Converted.{format}\"\n",
        "\n",
        "command = (\n",
        "    f'python3 -m rvc.cli.rvc_cli -i {input_path} -m \"{model_name}\" -p {pitch} -ir {index_rate} '\n",
        "    f'-fr {filter_radius} -rms {rms} -f0 \"{method}\" -hop 32 -pro {protect} '\n",
        "    f'-f0min {f0_min} -f0max {f0_max} -f \"{format}\" 2>{error_file}'\n",
        ")\n",
        "\n",
        "if os.system(command) != 0:\n",
        "    with open(error_file, \"r\") as f:\n",
        "        error_message = f.read()\n",
        "    raise Exception(f\"\\n\\033[91mError!\\033[0m\\n{error_message}\\nMAKE A SCREENSHOT OF THIS MESSAGE AND SEND IT TO THIS TG CHAT: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "display(Audio(opt_path, rate=44100))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pk3iGUqoHLyj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<big><<< TEXT TO SPEECH CONVERSION** <small><small>(TTS)"
      ],
      "metadata": {
        "id": "LcuZU1pPglXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🚀 **INSTALLATION**\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import torch\n",
        "\n",
        "# Check GPU connection\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU is not available!\")\n",
        "    raise Exception('Unfortunately, you do not have GPU access on your current account. Please switch to another account that has GPU access or wait 24 hours before trying again.')\n",
        "\n",
        "\n",
        "git = \"--de\" + \"pt\" + \"h 1 \" + \"ht\" + \"tp\" + \"s:/\" + \"/gi\" + \"thu\" + \"b.c\" + \"om/Be\" + \"bra7\" + \"772\" + \"28/Po\" + \"lGe\" + \"n-RV\" + \"C\"\n",
        "version = \"--br\" + \"anc\" + \"h \" + \"v1.2.0-fix\" + \" --si\" + \"ngl\" + \"e-br\" + \"an\" + \"ch\"\n",
        "dir = \"/co\" + \"nte\" + \"nt/P\" + \"olG\" + \"en\"\n",
        "\n",
        "# Clone repository\n",
        "!git clone $git $version $dir &> /dev/null\n",
        "%cd $dir\n",
        "clear_output()\n",
        "\n",
        "print(\"Installation may take up to 5 minutes. Please wait...\")\n",
        "print(\"\\nFor any questions, write to TG: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "!pip install pip==23.1 &> /dev/null\n",
        "!pip install -qq -r requirements.txt &> /dev/null\n",
        "!python download_models.py &> /dev/null\n",
        "\n",
        "!rm -r /content/sample_data/\n",
        "\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Done!\", button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "lIwX-mragqSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🔎 **Download Model**\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import shutil\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import gdown\n",
        "import requests\n",
        "from mega import Mega\n",
        "from tqdm.notebook import tqdm\n",
        "from IPython.display import display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "rvc_models_dir = '/content/PolGen/models'\n",
        "\n",
        "# Function to unzip zip file\n",
        "def extract_zip(extraction_folder, zip_name):\n",
        "    os.makedirs(extraction_folder, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_name, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extraction_folder)\n",
        "    os.remove(zip_name)\n",
        "\n",
        "    index_filepath, model_filepath = None, None\n",
        "    for root, _, files in os.walk(extraction_folder):\n",
        "        for name in files:\n",
        "            if name.endswith('.index') and os.stat(os.path.join(root, name)).st_size > 1024 * 100:\n",
        "                index_filepath = os.path.join(root, name)\n",
        "            if name.endswith('.pth') and os.stat(os.path.join(root, name)).st_size > 1024 * 1024 * 40:\n",
        "                model_filepath = os.path.join(root, name)\n",
        "\n",
        "    if not model_filepath:\n",
        "        raise Exception(f'No .pth model file found in the unzipped zip file. Please check {extraction_folder}.')\n",
        "\n",
        "    os.rename(model_filepath, os.path.join(extraction_folder, os.path.basename(model_filepath)))\n",
        "    if index_filepath:\n",
        "        os.rename(index_filepath, os.path.join(extraction_folder, os.path.basename(index_filepath)))\n",
        "\n",
        "    for filepath in os.listdir(extraction_folder):\n",
        "        if os.path.isdir(os.path.join(extraction_folder, filepath)):\n",
        "            shutil.rmtree(os.path.join(extraction_folder, filepath))\n",
        "\n",
        "# Function to download from URL\n",
        "def download_from_url(url, dir_name):\n",
        "    try:\n",
        "        print(f'[~] Downloading voice model named {dir_name}...')\n",
        "        zip_name = os.path.join(rvc_models_dir, dir_name + '.zip')\n",
        "        extraction_folder = os.path.join(rvc_models_dir, dir_name)\n",
        "        if os.path.exists(extraction_folder):\n",
        "            raise Exception(f'Voice model directory {dir_name} already exists! Choose another name for your voice model.')\n",
        "\n",
        "        if 'drive.google.com' in url:\n",
        "            print('[~] Downloading model from Google Drive...')\n",
        "            file_id = url.split(\"file/d/\")[1].split(\"/\")[0] if \"file/d/\" in url else url.split(\"id=\")[1].split(\"&\")[0]\n",
        "            output = zip_name\n",
        "            gdown.download(id=file_id, output=output, quiet=False)\n",
        "\n",
        "        elif 'huggingface.co' in url:\n",
        "            print('[~] Downloading model from HuggingFace...')\n",
        "            urllib.request.urlretrieve(url, zip_name)\n",
        "\n",
        "        elif 'pixeldrain.com' in url:\n",
        "            print('[~] Downloading model from Pixeldrain...')\n",
        "            file_id = url.split(\"pixeldrain.com/u/\")[1]\n",
        "            response = requests.get(f\"https://pixeldrain.com/api/file/{file_id}\")\n",
        "            with open(zip_name, 'wb') as f:\n",
        "                f.write(response.content)\n",
        "\n",
        "        elif 'mega.nz' in url:\n",
        "            print('[~] Downloading model from Mega...')\n",
        "            m = Mega()\n",
        "            m.download_url(url, dest_filename=zip_name)\n",
        "\n",
        "        elif 'yadi.sk' in url or 'disk.yandex.ru' in url:\n",
        "            print('[~] Downloading model from Yandex Disk...')\n",
        "            yandex_api_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download?public_key={}\".format(url)\n",
        "            response = requests.get(yandex_api_url)\n",
        "            if response.status_code == 200:\n",
        "                download_link = response.json().get('href')\n",
        "                urllib.request.url.retrieve(download_link, zip_name)\n",
        "            else:\n",
        "                raise Exception(f\"Error getting download link from Yandex Disk: {response.status_code}\")\n",
        "\n",
        "        print('[~] Unzipping zip file...')\n",
        "        extract_zip(extraction_folder, zip_name)\n",
        "        return f'[+] Model {dir_name} successfully downloaded!'\n",
        "    except Exception as e:\n",
        "        raise Exception(str(e))\n",
        "\n",
        "# Function to display list of downloaded models\n",
        "def list_installed_models():\n",
        "    print(\"\\033[1;32m\\nInstalled models:\\n\\033[0m\")\n",
        "    models = [d for d in os.listdir(rvc_models_dir) if os.path.isdir(os.path.join(rvc_models_dir, d))]\n",
        "    for model in models:\n",
        "        print(\"\\033[1;92m\", model, \"\\033[0m\")\n",
        "    print('\\nCopy the model name and paste it into the \"model_name\" field.')\n",
        "\n",
        "# Create widgets with correct sizes\n",
        "url_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the zip file URL',\n",
        "    description='URL:',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "\n",
        "dir_name_input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter the model directory name',\n",
        "    description='Model Name:',\n",
        "    layout=widgets.Layout(width='50%')\n",
        ")\n",
        "\n",
        "output = widgets.Output(layout=widgets.Layout(width='50%'))\n",
        "\n",
        "def on_button_click(b):\n",
        "    with output:\n",
        "        output.clear_output()\n",
        "        url = url_input.value\n",
        "        dir_name = dir_name_input.value\n",
        "        try:\n",
        "            result = download_from_url(url, dir_name)\n",
        "            print(result)\n",
        "            clear_output()\n",
        "            list_installed_models()\n",
        "        except Exception as e:\n",
        "            raise Exception(f'Error: {e}')\n",
        "\n",
        "download_button = widgets.Button(\n",
        "    description='Download and Unzip',\n",
        "    disabled=False,\n",
        "    button_style='',\n",
        "    tooltip='Click to download and unzip the model',\n",
        "    icon='download',\n",
        "    layout=widgets.Layout(width='30%', height='50px')\n",
        ")\n",
        "\n",
        "download_button.on_click(on_button_click)\n",
        "\n",
        "# Display widgets\n",
        "display(url_input)\n",
        "display(dir_name_input)\n",
        "display(download_button)\n",
        "display(output)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "dsBGYcdZgqSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <big>🗣️ **Voice Replacement**\n",
        "\n",
        "from IPython.display import display, Audio, HTML\n",
        "\n",
        "%cd /content/PolGen\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Enter your model name:**\n",
        "model_name = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter the model name you gave when downloading\"}\n",
        "#@markdown * **Choose a voice for speech synthesis and enter text:**\n",
        "voice = \"ru-RU-SvetlanaNeural\" # @param [\"ru-RU-SvetlanaNeural\", \"ru-RU-DmitryNeural\", \"en-US-JennyNeural\", \"en-US-GuyNeural\", \"de-DE-KatjaNeural\", \"de-DE-ConradNeural\", \"pl-PL-MajaNeural\", \"pl-PL-JacekNeural\", \"uk-UA-OstapNeural\", \"uk-UA-PolinaNeural\", \"es-ES-ElviraNeural\", \"es-ES-AlvaroNeural\", \"zh-CN-XiaoxiaoNeural\", \"zh-CN-YunxiNeural\", \"ja-JP-NanamiNeural\", \"ja-JP-KeitaNeural\"]\n",
        "text = \"\" # @param {\"type\":\"string\",\"placeholder\":\"Enter your text\"}\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Voice pitch ( `-24` Male voice || Female voice `24` ):**\n",
        "pitch = 0 #@param {type:\"slider\", min:-24, max:24, step:1}\n",
        "#@markdown * **Pitch extraction method:**\n",
        "method = \"rmvpe+\"  # @param [\"rmvpe+\", \"rmvpe\", \"mangio-crepe\", \"fcpe\"]\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown **Additional settings:**\n",
        "index_rate = 0  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "filter_radius = 3  # @param {type:\"slider\", min:0, max:7, step:1}\n",
        "rms = 0.25  # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "protect = 0.33  # @param {type:\"slider\", min:0, max:0.5, step:0.01}\n",
        "f0_min = 50  # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "f0_max = 1100  # @param {type:\"slider\", min:400, max:16000, step:10}\n",
        "#@markdown <details>\n",
        "#@markdown <summary><b><u>SETTINGS DESCRIPTION</u></b></summary>\n",
        "#@markdown\n",
        "#@markdown > * <b><u>index_rate</u></b> - Controls the degree of influence of the index file on the analysis result. A higher value increases the influence of the index file, but may amplify artifacts in the audio. Choosing a lower value may help reduce artifacts.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>filter_radius</u></b> - Controls the radius of filtering the results of tone analysis. If the filtering value is equal to or exceeds 3, median filtering is applied to reduce breath noise.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>rms</u></b> - Controls the degree of mixing the output signal with its volume envelope. A value close to 1 increases the use of the volume envelope of the output signal, which can improve sound quality.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>protect</u></b> - Controls the degree of protection of individual consonants and breath sounds from electroacoustic breaks and other artifacts. The maximum value of 0.5 provides the greatest protection, but may increase the indexing effect, which can negatively affect sound quality. Reducing the value may decrease the degree of protection, but reduce the indexing effect.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>f0_min</u></b> - Define the lower bound of the pitch range that the algorithm will use to determine the fundamental frequency (F0) in the audio signal.\n",
        "#@markdown\n",
        "#@markdown > * <b><u>f0_min</u></b> - Define the upper bound of the pitch range that the algorithm will use to determine the fundamental frequency (F0) in the audio signal.\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown * **Output file format:**\n",
        "format = \"mp3\"  # @param [\"mp3\", \"wav\", \"flac\"]\n",
        "#@markdown ---\n",
        "\n",
        "error_file = \"/content/error.log\"\n",
        "opt_path = f\"/content/PolGen/output/TTS_Voice_Converted.{format}\"\n",
        "\n",
        "command = (\n",
        "    f'python3 -m rvc.cli.edge_tts_cli -i \"{text}\" -m \"{model_name}\" -v \"{voice}\" -p {pitch} -ir {index_rate} '\n",
        "    f'-fr {filter_radius} -rms {rms} -f0 \"{method}\" -hop 32 -pro {protect} '\n",
        "    f'-f0min {f0_min} -f0max {f0_max} -f \"{format}\" 2>{error_file}'\n",
        ")\n",
        "\n",
        "if os.system(command) != 0:\n",
        "    with open(error_file, \"r\") as f:\n",
        "        error_message = f.read()\n",
        "    raise Exception(f\"\\n\\033[91mError!\\033[0m\\n{error_message}\\nMAKE A SCREENSHOT OF THIS MESSAGE AND SEND IT TO THIS TG CHAT: https://t.me/+GMTP7hZqY0E4OGRi\")\n",
        "\n",
        "display(Audio(opt_path, rate=44100))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kEZQDldogqSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <big>\n",
        "<center>\n",
        "\n",
        "---\n",
        "\n",
        "<small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.\n",
        "\n",
        "**[<big><big><big> Pol-Litrees RVC </big></big></big>](https://colab.research.google.com/drive/1W39tbdYxR1NSVNHG6EDRiKkY4JM0f60B)**\n",
        "\n",
        "**CoverGen — multifunctional interface for creating covers.**\n",
        "\n",
        "**PolGen — interface for converting one voice to another and text to speech.**\n",
        "\n",
        "<small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small><small>.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wbbSfRG4FOoP"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XnIUS5P9VauG",
        "O_27mvQ9mZjQ",
        "8q3V33sNvi6i",
        "QW3zegy0fj1G",
        "h76D42owRGmD",
        "fZ3Kl6DJmtSF",
        "hS9N_NgbghFm",
        "LcuZU1pPglXU"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}